x <- runif(100,-2,2)
y <- cos(0.6*x)
plot(x,y)
library("ISLR2")
install.packages("ISLR2")#
library("ISLR2")
Boston
names(Boston)#
lmfit_B1 <- lm(crim~zn, data = Boston)#
lmfit_B2 <- lm(crim~indus, data = Boston)#
lmfit_B3 <- lm(crim~chas, data = Boston)#
lmfit_B4 <- lm(crim~nox, data = Boston)#
lmfit_B5 <- lm(crim~rm, data = Boston)#
lmfit_B6 <- lm(crim~age, data = Boston)#
lmfit_B7 <- lm(crim~dis, data = Boston)#
lmfit_B8 <- lm(crim~rad, data = Boston)#
lmfit_B9 <- lm(crim~tax, data = Boston)#
lmfit_B10 <- lm(crim~ptratio, data = Boston)#
lmfit_B11 <- lm(crim~lstat, data = Boston)#
lmfit_B12 <- lm(crim~medv, data = Boston)#
#
summary(lmfit_B1)#
summary(lmfit_B2)#
summary(lmfit_B3)#
summary(lmfit_B4)#
summary(lmfit_B5)#
summary(lmfit_B6)#
summary(lmfit_B7)#
summary(lmfit_B8)#
summary(lmfit_B9)#
summary(lmfit_B10)#
summary(lmfit_B11)#
summary(lmfit_B12)
lmfit_Boston <- lm(crim~ ., data = Boston)#
summary(lmfit_Boston)#
#
# We can reject the null hypothesis for B_2, B_3, B_4, B_5, B_6, B_9, B_10, B_11#
#
# c#
# There seem to be significant differences in the results from a and b. There are different statistically significant variables for each one#
lm_vect <- c(lmfit_B1, lmfit_B2, lmfit_B3, lmfit_B4, lmfit_B5, lmfit_B6, lmfit_B7, lmfit_B8, lmfit_B9, lmfit_B10, lmfit_B11, lmfit_B12)#
plot(x = lm_vect, y = lmfit_Boston)#
#
# d#
lmfit2_B1 <- (crim~zn + I(zn^2) + I(zn^3))#
summary(lmfit2_B1)
lmfit2_B1 <- lm(crim~zn + I(zn^2) + I(zn^3),data=Boston)
summary(lmfit2_B1)
lmfit2_B1 <- lm(crim~zn + I(zn^2) + I(zn^3),data=Boston)#
anova(lmfit_B1,lmfit2_B1)
set.seed(1)#
x <- rnorm(100)#
## Part (b) #
eps <- rnorm(100,0.5)#
## Part (c)#
Y<- -1 + 0.5*x + eps#
## Part (d)#
plot(x,Y)#
## Part (e)#
lm_2e <- lm(Y~x)#
summary(lm_2e)#
## Part(f)#
plot(x,Y)#
abline(a=-1,b=0.5)#
abline(a=lm_2e$coef[1],b=lm_2e$coef[2],col=2,lty=2)#
legend("topleft",c("Population","Least Squares"),col=c(1,2),lty=c(1,2))#
#
## Part (g)#
lm_2g <- lm(Y~x+I(x^2))
summary(lm_2g)
set.seed(1)#
x <- rnorm(100)#
eps <- rnorm(100,0.1)#
Y<- -1 + 0.5*x + eps#
plot(x,Y)#
lm_2h <- lm(Y~x)#
summary(lm_2h)#
plot(x,Y)#
abline(a=-1,b=0.5)#
abline(a=lm_2h$coef[1],b=lm_2h$coef[2],col=2,lty=2)#
legend("topleft",c("Population","Least Squares"),col=c(1,2),lty=c(1,2))
set.seed(1)#
x <- rnorm(100)#
## Part (b) #
eps <- rnorm(100,0, 0.5)#
## Part (c)#
Y<- -1 + 0.5*x + eps#
## Part (d)#
plot(x,Y)#
## Part (e)#
lm_2e <- lm(Y~x)#
summary(lm_2e)#
## Part(f)#
plot(x,Y)#
abline(a=-1,b=0.5)#
abline(a=lm_2e$coef[1],b=lm_2e$coef[2],col=2,lty=2)#
legend("topleft",c("Population","Least Squares"),col=c(1,2),lty=c(1,2))#
#
## Part (g)#
lm_2g <- lm(Y~x+I(x^2))#
summary(lm_2g)
plot(x,Y)
set.seed(1)#
x <- rnorm(100)#
eps <- rnorm(100, 0, 0.1)#
Y<- -1 + 0.5*x + eps#
plot(x,Y)#
lm_2h <- lm(Y~x)#
summary(lm_2h)#
plot(x,Y)#
abline(a=-1,b=0.5)#
abline(a=lm_2h$coef[1],b=lm_2h$coef[2],col=2,lty=2)#
legend("topleft",c("Population","Least Squares"),col=c(1,2),lty=c(1,2))
set.seed(1)#
x <- rnorm(100)#
eps <- rnorm(100,0, 1)#
Y<- -1 + 0.5*x + eps#
plot(x,Y)#
lm_2i <- lm(Y~x)#
summary(lm_2i)#
plot(x,Y)#
abline(a=-1,b=0.5)#
abline(a=lm_2i$coef[1],b=lm_2i$coef[2],col=2,lty=2)#
legend("topleft",c("Population","Least Squares"),col=c(1,2),lty=c(1,2))
lm_2e$coef
names(lm_2e)
lm_2e$coefficients
?lm
vcov(lm_2e)
lm_2e$coef - qt(0.975,98)*sqrt(diag(vcov(lm_2e)))
leftlimits_2e <- lm_2e$coef - qt(0.975,98)*sqrt(diag(vcov(lm_2e)))#
rightlimits_2e <- lm_2e$coef + qt(0.975,98)*sqrt(diag(vcov(lm_2e)))#
coefintvals_2e <- cbind(leftlimits_2e,rightlimits_2e)
coefintvals_2e
leftlimits_2h <- lm_2h$coef - qt(0.975,98)*sqrt(diag(vcov(lm_2h)))#
rightlimits_2h <- lm_2h$coef + qt(0.975,98)*sqrt(diag(vcov(lm_2h)))#
coefintvals_2h <- cbind(leftlimits_2h,rightlimits_2h)
coefintvals_2h
leftlimits_2i <- lm_2i$coef - qt(0.975,98)*sqrt(diag(vcov(lm_2i)))#
rightlimits_2i <- lm_2i$coef + qt(0.975,98)*sqrt(diag(vcov(lm_2i)))#
coefintvals_2i <- cbind(leftlimits_2i,rightlimits_2i)
coefintvals_2i
library("ISLR2")#
attach(Boston)
head(Boston)
?Boston
head(Boston,100)
?Boston
dim(Boston)
is.numeric(Boston$rad)
names(Boston)
x.names <- names(Boston)[2]
x.names
lm(Boston$crim~Boston$x.names)
lm(crim~x.names, data=Boston)
lm(crim~`x.names', data=Boston)
)
''
1
}
``
)
}
'()'
''
lm(crim~'x.names', data=Boston)
fm <- paste0("crim","~",colnames(Boston)[i])
i <- 2
fm <- paste0("crim","~",colnames(Boston)[i])
fm
colnames(Boston)[i]!%c("chas","rad")
colnames(Boston)[i]!%in%c("chas","rad")
colnames(Boston)[i]
!colnames(Boston)[i]%in%c("chas","rad")
i <- 4
fm <- paste0("crim","~ as.factor(",colnames(Boston)[i],")")
fm
lm_i <- lm(as.formula(fm),data=Boston)#
    summary(lm_i)
Boston$chas
for (i in c(2:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~",colnames(Boston)[i])#
    lm_i <- lm(as.formula(fm),data=Boston)#
    summary(lm_i)#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~ as.factor(",colnames(Boston)[i],")")#
    lm_i <- lm(as.formula(fm),data=Boston)#
    summary(lm_i)#
  }#
}
for (i in c(2:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~",colnames(Boston)[i])#
    lm_i <- lm(as.formula(fm),data=Boston)#
    cat(summary(lm_i))#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~ as.factor(",colnames(Boston)[i],")")#
    lm_i <- lm(as.formula(fm),data=Boston)#
    cat(summary(lm_i))#
  }#
}
for (i in c(2:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~",colnames(Boston)[i])#
    lm_i <- lm(as.formula(fm),data=Boston)#
    print(summary(lm_i))#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~ as.factor(",colnames(Boston)[i],")")#
    lm_i <- lm(as.formula(fm),data=Boston)#
    print(summary(lm_i))#
  }#
}
par(mfrow=c(4,3))#
for (i in c(2:13))#
{#
   x <- Boston[i]#
   plot(x,Boston$crim,xlab=colnames(Boston)[i],ylab="Per Capita Crime Rate")#
}
x <- Boston[,i]
i
plot(x,Boston$crim,xlab=colnames(Boston)[i],ylab="Per Capita Crime Rate")
par(mfrow=c(4,3))#
for (i in c(2:13))#
{#
   x <- Boston[,i]#
   plot(x,Boston$crim,xlab=colnames(Boston)[i],ylab="Per Capita Crime Rate")#
}
par(mfrow=c(4,3))#
for (i in c(2:13))#
{#
   x <- Boston[,i]#
   plot(x,Boston$crim,xlab=colnames(Boston)[i],ylab="Crime Rate")#
}
fm <- paste0("crim","~", colnames(Boston)[2])
fm
fm <- paste0("crim","~", colnames(Boston)[2])#
for (i in c(3:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0(fm, "+", colnames(Boston)[i])#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0(fm, "+", "~ as.factor(",colnames(Boston)[i],")")#
  }#
}
fm
fm <- paste0("crim","~", colnames(Boston)[2])#
for (i in c(3:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0(fm, "+", colnames(Boston)[i])#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0(fm,"+","as.factor(",colnames(Boston)[i],")")#
  }#
}
fm
fm <- paste0("crim","~", colnames(Boston)[2])#
for (i in c(3:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0(fm, "+", colnames(Boston)[i])#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0(fm,"+","as.factor(",colnames(Boston)[i],")")#
  }#
}#
#
multilm <- lm (as.formula(fm),data=Boston)
summary(multilm)
fm1 <- paste0("crim","~", colnames(Boston)[2])#
for (i in c(3:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm1 <- paste0(fm1, "+", colnames(Boston)[i])#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    if (colnames(Boston)[i]=="chas")#
    {fm1 <- paste0(fm1,"+","as.factor(",colnames(Boston)[i],")")}#
  }#
}
fm1
multilm2 <- lm (as.formula(fm1),data=Boston)
summary(multilm2)
anova(multilm2, multilm)
coef_sim <- NULL#
for (i in c(2:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~",colnames(Boston)[i])#
    lm_i <- lm(as.formula(fm),data=Boston)#
    coef_sim <- c(coef_sim, lm_i$coef[2])#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~ as.factor(",colnames(Boston)[i],")")#
    lm_i <- lm(as.formula(fm),data=Boston)#
    coef_sim <- c(coef_sim, lm_i$coef[2])#
  }#
}
coef_sim
coef_sim <- NULL#
for (i in c(2:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~",colnames(Boston)[i])#
    lm_i <- lm(as.formula(fm),data=Boston)#
    coef_sim <- c(coef_sim, lm_i$coef[2])#
  }#
  if (colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm <- paste0("crim","~ as.factor(",colnames(Boston)[i],")")#
    lm_i <- lm(as.formula(fm),data=Boston)#
    coef_sim <- c(coef_sim, lm_i$coef[-1])#
  }#
}
coef_sim
coef_mult <- multilm$coef[-1]
coef_mult
plot(coef_sim,coef_mult)
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult)
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+1, labels=colnames(coef_mult))
colnames(coef_mult)
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+1, labels=names(coef_mult))
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+0.1, labels=colnames(coef_mult))
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+0.1, labels=names(coef_mult))
coef_mult <- multilm$coef[-1]#
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+0.1, labels=c(1:length(coef_sim)))
coef_mult <- multilm$coef[-1]#
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+0.2, labels=c(1:length(coef_sim)))
par(mfrow=c(1,1))#
plot(coef_sim,coef_mult,xlab="Simple Linear Model Coefficients",ylab="Multiple Linear Model Coefficients")#
text(coef_sim, coef_mult+0.4, labels=c(1:length(coef_sim)))
length(coef_sim)
i
i <- 2
fm <- paste0("crim","~",colnames(Boston)[i], "+I(", colnames(Boston)[i], "^2)", "+I(", colnames(Boston)[i],"^3)")
fm
lm_i <- lm(as.formula(fm),data=Boston)
print(summary(lm_i))
for (i in c(2:13))#
{#
  if (!colnames(Boston)[i]%in%c("chas","rad"))#
  {#
    fm3 <- paste0("crim","~",colnames(Boston)[i], "+I(", colnames(Boston)[i], "^2)", "+I(", colnames(Boston)[i],"^3)")#
    lm3_i <- lm(as.formula(fm3),data=Boston)#
    print(summary(lm3_i))#
    fm1 <- paste0("crim","~",colnames(Boston)[i])#
    lm1_i <- lm(as.formula(fm1),data=Boston)#
    print(anova(lm1_i,lm3_i))#
  }#
}
library("ISLR2")#
attach(Carseats)#
Urban.fac <- as.factor(Carseats$Urban)#
US.fac <- as.factor(Carseats$US)#
lm_a <- lm(Carseats$Sales ~ Carseats$Price + Urban.fac + US.fac)#
summary(lm_a)
lm_e <- lm(Carseats$Sales ~ Carseats$Price+ US.fac)#
summary(lm_e)
anova(Carseats$Sales~Urban.fac)
anova(Carseats$Sales~Carseats$Urbab)
anova(Carseats$Sales~Carseats$Urban)
lm1 <- lm(Carseats$Sales ~ US.fac)
lm1
anova(lm1)
anova(lm1)[1,5]
anova(Carseats$Sales, Carseats$Urban)
anova(Carseats$Sales, US.fac)
Urban.fac <- as.factor(Carseats$Urban)#
US.fac <- as.factor(Carseats$US)#
lm_a <- lm(Carseats$Sales ~ Carseats$Price + Urban.fac + US.fac)#
summary(lm_a)#
## Part (e)#
lm_e <- lm(Carseats$Sales ~ Carseats$Price+ US.fac)#
summary(lm_e)#
par(mfrow=c(1,3))#
plot(lm_a$fitted,Carseats$Sales)#
plot(lm_a$fitted,lm_a$residuals)#
plot(lm_e$fitted,lm_e$residuals)
leftlimits_1g <- lm_e$coef - qt(0.975,397)*sqrt(diag(vcov(lm_e)))#
rightlimits_1g <- lm_e$coef + qt(0.975,397)*sqrt(diag(vcov(lm_e)))#
coefintvals_1g <- cbind(leftlimits_1g,rightlimits_1g)
coefintvals_1g
library("lars")#
data(diabetes)#
x <- diabetes$x#
y <- diabetes$y#
male <- unique(x[,"sex"])[2]#
sex <- 1*(x[,"sex"]==male)#
x[,"sex"] <- sex#
#
diabetes.dat=data.frame(y=y, age=as.numeric(x[,"age"]), sex=as.factor(x[,"sex"]), bmi=as.numeric(x[,"bmi"]), map=as.numeric(x[,"map"]), #
    tc=as.numeric(x[,"tc"]), ldl=as.numeric(x[,"ldl"]), hdl=as.numeric(x[,"hdl"]), tch=as.numeric(x[,"tch"]), ltg=as.numeric(x[,"ltg"]), glu=as.numeric(x[,"glu"]))#
fullmod=lm(y~.,data=diabetes.dat)#
summary(fullmod)#
## Stepwise AIC selection#
library(MASS)#
stepmod=lm(y~.,data=diabetes.dat)#
AICmod=stepAIC(stepmod,direction="both",trace=1)#
summary(AICmod)
BICmod=stepAIC(stepmod,k=log(dim(statedata)[1]),trace=1)#
summary(BICmod)
BICmod=stepAIC(stepmod,k=log(dim(diabetes.dat)[1]),trace=1)#
summary(BICmod)
diabetes
?diabetes
library("lars")#
data(diabetes)#
x <- diabetes$x#
y <- diabetes$y#
male <- unique(x[,"sex"])[2]#
sex <- 1*(x[,"sex"]==male)#
x[,"sex"] <- sex#
#
diabetes.dat=data.frame(y=y, age=as.numeric(x[,"age"]), sex=as.factor(x[,"sex"]), bmi=as.numeric(x[,"bmi"]), map=as.numeric(x[,"map"]), #
    tc=as.numeric(x[,"tc"]), ldl=as.numeric(x[,"ldl"]), hdl=as.numeric(x[,"hdl"]), tch=as.numeric(x[,"tch"]), ltg=as.numeric(x[,"ltg"]), glu=as.numeric(x[,"glu"]))
head(diabetes.dat)
head(round(diabetes.dat,4))
?round
> head(diabetes.dat)#
    y          age sex         bmi          map           tc         ldl          hdl          tch          ltg          glu#
1 151  0.038075906   0  0.06169621  0.021872355 -0.044223498 -0.03482076 -0.043400846 -0.002592262  0.019908421 -0.017646125#
2  75 -0.001882017   1 -0.05147406 -0.026327835 -0.008448724 -0.01916334  0.074411564 -0.039493383 -0.068329744 -0.092204050#
3 141  0.085298906   0  0.04445121 -0.005670611 -0.045599451 -0.03419447 -0.032355932 -0.002592262  0.002863771 -0.025930339#
4 206 -0.089062939   1 -0.01159501 -0.036656447  0.012190569  0.02499059 -0.036037570  0.034308859  0.022692023 -0.009361911#
5 135  0.005383060   1 -0.03638469  0.021872355  0.003934852  0.01559614  0.008142084 -0.002592262 -0.031991445 -0.046640874#
6  97 -0.092695478   1 -0.04069594 -0.019442093 -0.068990650 -0.07928784  0.041276824 -0.076394504 -0.041180385 -0.096346157
diabetes.dat=data.frame(y=y, age=as.numeric(x[,"age"]), sex=as.factor(x[,"sex"]), bmi=as.numeric(x[,"bmi"]), map=as.numeric(x[,"map"]), #
    tc=as.numeric(x[,"tc"]), ldl=as.numeric(x[,"ldl"]), hdl=as.numeric(x[,"hdl"]), tch=as.numeric(x[,"tch"]), ltg=as.numeric(x[,"ltg"]), glu=as.numeric(x[,"glu"]))#
fullmod=lm(y~.,data=diabetes.dat)#
summary(fullmod)#
## Stepwise AIC selection#
library(MASS)#
stepmod=lm(y~.,data=diabetes.dat)#
AICmod=stepAIC(stepmod,direction="both",trace=1)#
summary(AICmod)#
## Stepwise BIC selection#
BICmod=stepAIC(stepmod,k=log(dim(diabetes.dat)[1]),trace=1)#
summary(BICmod)
mod=stepAIC(stepmod,direction="both",trace=1)#
summary(mod)
vcov(mod)
round(vcov(mod),3)
BreastCancer0<- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"), header=FALSE)#
colnames(BreastCancer0)<-c("class","age","menopause","tumorsize","invnodes","nodecaps","degmalig","breast","breastquad","irradiat")#
BreastCancer <- BreastCancer0[,-c(3,4,5,9)]#
missingrows <- which(BreastCancer$nodecaps=="?")#
NewBreastCancer <- BreastCancer[-missingrows,]#
NewBreastCancer$class<-(NewBreastCancer$class=="recurrence-events")+0#
NewBreastCancer$nodecaps<-as.factor(NewBreastCancer$nodecaps)#
NewBreastCancer$irradiat<-as.factor(NewBreastCancer$irradiat)#
#
##table(NewBreastCancer$nodecaps,NewBreastCancer$irradiat,NewBreastCancer$class)#
## Logistic regression#
logitmod<-glm(class~age+nodecaps,data=NewBreastCancer,family="binomial")#
summary(logitmod)
head(BreastCancer)
unique(BreastCancer$age)
BreastCancer0<- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"), header=FALSE)#
colnames(BreastCancer0)<-c("class","age","menopause","tumorsize","invnodes","nodecaps","degmalig","breast","breastquad","irradiat")#
BreastCancer <- BreastCancer0[,-c(3,4,5,9)]#
missingrows <- which(BreastCancer$nodecaps=="?")#
NewBreastCancer <- BreastCancer[-missingrows,]#
NewBreastCancer$class<-(NewBreastCancer$class=="recurrence-events")+0#
NewBreastCancer$nodecaps<-as.factor(NewBreastCancer$nodecaps)#
NewBreastCancer$irradiat<-as.factor(NewBreastCancer$irradiat)#
NewBreastCancer$age <- 1*(NewBreastCancer$age == "30-39") + 2*(NewBreastCancer$age == "30-39") + 3*(NewBreastCancer$age == "40-49") + 4*(NewBreastCancer$age == "50-59") #
 + 5*(NewBreastCancer$age == "60-69") + 6*(NewBreastCancer$age == "60-69")#
#
##table(NewBreastCancer$nodecaps,NewBreastCancer$irradiat,NewBreastCancer$class)#
## Logistic regression#
logitmod<-glm(class~age+nodecaps,data=NewBreastCancer,family="binomial")#
summary(logitmod)
logitmod<-glm(class ~ nodecaps + irradiat,data=NewBreastCancer,family="binomial")#
summary(logitmod)
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,])#
n1<-sum(NewBreastCancer$class==1)#
n2<-sum(NewBreastCancer$class==0)#
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,c("age","degmalig")])
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,c("age","degmalig")])#
n1<-sum(NewBreastCancer$class==1)#
n2<-sum(NewBreastCancer$class==0)#
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)#
invSn<-solve(Spooled)#
ahat<-as.numeric(groupmeans[2,2:3]-groupmeans[1,2:3])%*%invSn#
mhat<-ahat%*%as.numeric(groupmeans[1,2:3]+groupmeans[2,2:3])/2
mhat
ahat
## LDA#
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,c("age","degmalig")])#
n1<-sum(NewBreastCancer$class==1)#
n2<-sum(NewBreastCancer$class==0)#
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)#
invSn<-solve(Spooled)#
ahat<-as.numeric(groupmeans[2,2:3]-groupmeans[1,2:3])%*%invSn#
mhat<-ahat%*%as.numeric(groupmeans[1,2:3]+groupmeans[2,2:3])/2#
#
## Logistic regression model#
logitmod2<-glm(class ~ age + degmalig,data=NewBreastCancer,family="binomial")#
summary(logitmod2)
groupmeans
invSn
BreastCancer0<- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"), header=FALSE)#
colnames(BreastCancer0)<-c("class","age","menopause","tumorsize","invnodes","nodecaps","degmalig","breast","breastquad","irradiat")#
BreastCancer <- BreastCancer0[,-c(3,4,5,9)]#
missingrows <- which(BreastCancer$nodecaps=="?")#
NewBreastCancer <- BreastCancer[-missingrows,]#
NewBreastCancer$class<-(NewBreastCancer$class=="recurrence-events")+0#
NewBreastCancer$nodecaps<-as.factor(NewBreastCancer$nodecaps)#
NewBreastCancer$irradiat<-as.factor(NewBreastCancer$irradiat)#
NewBreastCancer$age <- 1*(NewBreastCancer$age == "20-29") + 2*(NewBreastCancer$age == "30-39") + 3*(NewBreastCancer$age == "40-49") + 4*(NewBreastCancer$age == "50-59") #
 + 5*(NewBreastCancer$age == "60-69") + 6*(NewBreastCancer$age == "60-69")#
## Logistic regression#
logitmod<-glm(class ~ nodecaps + irradiat,data=NewBreastCancer,family="binomial")#
summary(logitmod)#
#
## LDA#
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,c("age","degmalig")])#
n1<-sum(NewBreastCancer$class==1)#
n2<-sum(NewBreastCancer$class==0)#
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)#
invSn<-solve(Spooled)#
ahat<-as.numeric(groupmeans[2,2:3]-groupmeans[1,2:3])%*%invSn#
mhat<-ahat%*%as.numeric(groupmeans[1,2:3]+groupmeans[2,2:3])/2#
#
## Logistic regression model#
logitmod2<-glm(class ~ age + degmalig,data=NewBreastCancer,family="binomial")#
summary(logitmod2)
BreastCancer0<- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"), header=FALSE)#
colnames(BreastCancer0)<-c("class","age","menopause","tumorsize","invnodes","nodecaps","degmalig","breast","breastquad","irradiat")#
BreastCancer <- BreastCancer0[,-c(3,4,5,9)]#
missingrows <- which(BreastCancer$nodecaps=="?")#
NewBreastCancer <- BreastCancer[-missingrows,]#
NewBreastCancer$class<-(NewBreastCancer$class=="recurrence-events")+0#
NewBreastCancer$nodecaps<-as.factor(NewBreastCancer$nodecaps)#
NewBreastCancer$irradiat<-as.factor(NewBreastCancer$irradiat)#
NewBreastCancer$age <- 1*(NewBreastCancer$age == "20-29") + 2*(NewBreastCancer$age == "30-39") + 3*(NewBreastCancer$age == "40-49") + 4*(NewBreastCancer$age == "50-59") #
 + 5*(NewBreastCancer$age == "60-69") + 6*(NewBreastCancer$age == "70-79")#
## Logistic regression#
logitmod<-glm(class ~ nodecaps + irradiat,data=NewBreastCancer,family="binomial")#
summary(logitmod)#
#
## LDA#
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,c("age","degmalig")])#
n1<-sum(NewBreastCancer$class==1)#
n2<-sum(NewBreastCancer$class==0)#
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)#
invSn<-solve(Spooled)#
ahat<-as.numeric(groupmeans[2,2:3]-groupmeans[1,2:3])%*%invSn#
mhat<-ahat%*%as.numeric(groupmeans[1,2:3]+groupmeans[2,2:3])/2#
#
## Logistic regression model#
logitmod2<-glm(class ~ age + degmalig,data=NewBreastCancer,family="binomial")#
summary(logitmod2)
groupmeans<-aggregate(NewBreastCancer[,c("age","degmalig")], list(NewBreastCancer$class), mean)#
S1<-cov(NewBreastCancer[NewBreastCancer$class==1,c("age","degmalig")])#
S2<-cov(NewBreastCancer[NewBreastCancer$class==0,c("age","degmalig")])#
n1<-sum(NewBreastCancer$class==1)#
n2<-sum(NewBreastCancer$class==0)#
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)#
invSn<-solve(Spooled)
groupmeans
invSn
1.686^2
0.045765-0.188530
vcov <- matrix(c(1.945737e-06, -4.470395e-07, -4.470395e-07,  7.415335e-05 ),2,2)
vcov
cvec <- c(1,-1)
t(cvec)%*%vcov%*%cvec
-0.142765/sqrt(7.699317e-05)
-3.51271 - 0.04571*90 + 4.33896*1.68
CrimeData<- read.csv(url("http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data"), header=FALSE)#
##setwd("/Users/pszhong/Box Sync/UIC Teaching/STAT 385-2021/Lab Material/Lab 10")#
setwd("C:/Users/pszhong/Box/UIC\ Teaching/STAT\ 385-2022-Spring-Fall/Lab Material/Lab\ 10")
library(pls)#
library(lars)#
data(diabetes)#
attach(diabetes)#
#### fit a PLS model#
model <- plsr(diabetes$y~diabetes$x, data=diabetes, scale=TRUE, validation="CV")#
#view summary of model fitting#
summary(model)#
#visualize CV plots#
validationplot(model)#
validationplot(model, val.type="MSEP")#
validationplot(model, val.type="R2")#
#### fit a PCR model#
model_pcr <- pcr(diabetes$y~diabetes$x, data=diabetes, scale=TRUE, validation="CV")#
#view summary of model fitting#
summary(model_pcr)#
#visualize CV plots#
validationplot(model_pcr)
install.packages("pls")
library(pls)#
library(lars)#
data(diabetes)#
attach(diabetes)#
#### fit a PLS model#
model <- plsr(diabetes$y~diabetes$x, data=diabetes, scale=TRUE, validation="CV")#
#view summary of model fitting#
summary(model)#
#visualize CV plots#
validationplot(model)#
validationplot(model, val.type="MSEP")#
validationplot(model, val.type="R2")#
#### fit a PCR model#
model_pcr <- pcr(diabetes$y~diabetes$x, data=diabetes, scale=TRUE, validation="CV")#
#view summary of model fitting#
summary(model_pcr)#
#visualize CV plots#
validationplot(model_pcr)
?validationplot
#define training and testing sets#
set.seed(2022)#
nsample <- nrow(diabetes$x)#
train <- sample(1:nsample,360)#
train_x <- diabetes$x[train, ]#
train_y <- diabetes$y[train]#
test_y <- diabetes$y[-train]#
test_x <- diabetes$x[-train, ]#
#PLS: use model on training data and make predictions on a test set#
model_train <- plsr(train_y~train_x, scale=TRUE, validation="CV")#
validationplot(model_train)#
pred_pls <- predict(model_train, test_x, ncomp = 2)#
#prediction sum of squared errors#
pls_err <- sqrt(mean((pred_pls - test_y)^2))#
#PCR: use model on training data and make predictions on a test set#
model_train_pcr <- pcr(train_y~train_x, scale=TRUE, validation="CV")#
validationplot(model_train_pcr)#
pred_pcr <- predict(model_train_pcr, test_x, ncomp = 4)
pred_pcr
plot(train_y,pred_pcr)
length(pred_pcr)
length(train_y)
plot(test_y,pred_pcr)
pcr_err <- sqrt(mean((pred_pcr - test_y)^2))
pcr_err
model <- plsr(diabetes$y~diabetes$x, data=diabetes, scale=TRUE, validation="CV")#
#view summary of model fitting#
summary(model)#
#visualize CV plots#
validationplot(model)#
validationplot(model, val.type="MSEP")#
validationplot(model, val.type="R2")
validationplot(model)
validationplot(model, val.type="MSEP")
validationplot(model)
validationplot(model, val.type="R2")
model_train_pcr <- pcr(train_y~train_x, scale=TRUE, validation="CV")#
validationplot(model_train_pcr)#
pred_pcr <- predict(model_train_pcr, test_x, ncomp = 4)
plot(test_y,pred_pcr)
model_train <- plsr(train_y~train_x, scale=TRUE, validation="CV")#
validationplot(model_train)#
pred_pls <- predict(model_train, test_x, ncomp = 2)
plot(test_y,pred_pls)
pls_err <- sqrt(mean((pred_pls - test_y)^2))
pls_err
setwd("/Users/pszhong/Library/CloudStorage/Box-Box/UIC Teaching/STAT 385-2023-Fall/Data Sets/email spam")
## Read data sets#
features=scan(file="features.txt", what="character")
features
## Reform data sets#
len_features=length(features)#
nlen=len_features/2#
featureframe=data.frame(feature=features[2*(1:nlen)-1],type=features[2*(1:nlen)])
featureframe
featureframe[1,1]#
feature1vec=strsplit(as.character(featureframe[1,1]),split="_")#
feature1=feature1vec[[1]][3]#
feature1F=strsplit(feature1,split=":")[[1]][1]
feature1vec
feature1F
## Extract all the features#
allfeatures=matrix(0,nlen,1)#
for (i in 1:(nlen-3))#
{#
 feature1vec=strsplit(as.character(featureframe[i,1]),split="_")#
 feature1=feature1vec[[1]][3]#
 feature1F=strsplit(feature1,split=":")[[1]][1]#
 allfeatures[i]=feature1F#
}#
for (i in (nlen-2):nlen)#
{#
 feature55vec=strsplit(as.character(featureframe[i,1]),split="_")#
 feature55=feature55vec[[1]][4]#
 feature55F=strsplit(feature55,split=":")[[1]][1]#
 allfeatures[i]=feature55F#
}
allfeatures
Spamdata=read.table(file="spam.data.txt")
dim(Spamdata)
columnames=c(allfeatures,"SpamOrNot")
colnames(Spamdata)=columnames
head(Spamdata)
newSpamdata=Spamdata[,-c(55:57)]#
nnlen=dim(newSpamdata)[2]
Spamemails=newSpamdata[newSpamdata$SpamOrNot==1,]#
NonSpams=newSpamdata[newSpamdata$SpamOrNot==0,]#
SpamAves=colMeans(Spamemails)#
NonSpamAves=colMeans(NonSpams)#
AbsDifferences=abs(SpamAves-NonSpamAves)
AbsDifferences
SortbyAbsDifferences=sort(AbsDifferences[-(nnlen)],decreasing=TRUE)#
indexafterorder=order(AbsDifferences[-(nnlen)],decreasing=TRUE)#
summaryinfo=rbind((SpamAves[-(nnlen)])[indexafterorder],(NonSpamAves[-(nlen)])[indexafterorder],SortbyAbsDifferences)#
rownames(summaryinfo)=c("spam","email","abs diff")
summaryinfo
barplotinfo1=summaryinfo[1:2,1:27]#
barplotinfo2=summaryinfo[1:2,28:54]#
par(mfrow=c(2,1))#
barplot(barplotinfo1, main="Average frequencies of features by spam and non-spam",#
  xlab="Feature words or characters", col=c("darkblue","red"),#
  legend = rownames(barplotinfo1), beside=TRUE, ylim=c(0,2.3))#
barplot(barplotinfo2, xlab="Feature words or characters", col=c("darkblue","red"),#
  legend = rownames(barplotinfo2), beside=TRUE, ylim=c(0,2.3))
georgehp=(newSpamdata$george+newSpamdata$hp)/2
youyour=(newSpamdata$you+newSpamdata$your)/2
newSpamdatasub=cbind(georgehp,youyour,newSpamdata$SpamOrNot)#
par(mfrow=c(1,1))#
y=newSpamdata$SpamOrNot#
plot(newSpamdatasub[,1:2], col=y+1, pch=y+1, xlab="georgehp", ylab="youyour")
EntropyIG<-function(threshold,feature,classlabel,unit=exp(1))#
{#
nlen<-length(classlabel)#
probs0<-table(classlabel)/nlen#
entropyparent<-sum(-probs0*log(probs0,base=unit))#
featurecat<-(feature<threshold)*1+0#
Classtable<-table(featurecat,classlabel)#
props<-rowSums(Classtable)/sum(Classtable)#
probs<-Classtable/rowSums(Classtable)#
entropyele<-probs^(-probs)#
entropyprod<-apply(entropyele,1,prod)#
logentropy<-log(entropyprod,base=unit)#
entropychild<-sum(props*logentropy)#
IG<-entropyparent-entropychild#
return(IG)#
}
newSpamdatasub0<-data.frame(SpamOrNot=newSpamdata$SpamOrNot,georgehp=newSpamdatasub[,1], youyour=newSpamdatasub[,2])#
#newSpamdatasub0<-newSpamdatasub[,-1]#
## Q3: Compute information gain for both features "georegehp" and "youyour" at a sequence of threholds#
th1seq<-matrix(seq(0,max(newSpamdatasub0$georgehp),length=500),500,1)#
IGgeorgehp<-apply(th1seq,1,EntropyIG,feature=newSpamdatasub0$georgehp,classlabel=newSpamdatasub0$SpamOrNot)#
th1IGs<-cbind(th1seq,IGgeorgehp)#
plot(th1seq,IGgeorgehp,type="l",xlab="Threshold for feature georgehp",ylab="Entropy Information Gain")
th2seq<-matrix(seq(0,max(newSpamdatasub0$youyour),length=500),500,1)#
IGyouyour<-apply(th2seq,1,EntropyIG,feature=newSpamdatasub0$youyour,classlabel=newSpamdatasub0$SpamOrNot)#
th2IGs<-cbind(th2seq,IGgeorgehp)#
plot(th2seq,IGyouyour,type="l",xlab="Threshold for feature youyour",ylab="Entropy Information Gain")
max(IGyouyour)#
max(IGgeorgehp)
library(rpart)#
library(rpart.plot)#
treefit<-rpart(SpamOrNot~., data=newSpamdatasub0, method="class", parms=list(split = "information"),control = rpart.control(minsplit=10))#
treefit$split#
prp(treefit,type=2,extra=1)
759.6085559/4601
th1seq<-matrix(seq(0,2,length=100),100,1)#
th2seq<-matrix(seq(0,4,length=100),100,1)#
xgrid<-expand.grid(georgehp=th1seq,youyour=th2seq)#
predtions<-predict(treefit,newdata=xgrid,type="prob")[,2]#
ygrid<-(predtions>0.5)*1+0#
plot(xgrid, col=as.numeric(ygrid)+2, pch = 20, cex = .2,xlim=c(0,2),ylim=c(0,4))#
points(newSpamdatasub0$georgehp,newSpamdatasub0$youyour,pch=20, cex=1.2,col=newSpamdatasub0$SpamOrNot+2)#
contour(th1seq,th2seq,matrix(predtions,100,100),levels = .5,add=TRUE)
treefit1<-rpart(as.factor(SpamOrNot)~., data=newSpamdatasub0, method="class", parms=list(split = "information"),control = rpart.control(minsplit=10,cp=0.03))
printcp(treefit1)
prp(treefit1,type=2,extra=1)
treefit2<- rpart(as.factor(SpamOrNot)~ ., data=newSpamdatasub0, control=rpart.control(minsplit = 2, minbucket = 1, cp=0))#
bestcp <- treefit2$cptable[which.min(treefit2$cptable[,"xerror"]),"CP"]
treefit2$cptable
bestcp
tree.pruned <- prune(treefit2, cp = bestcp)#
prp(tree.pruned,type=2,extra=1)
predvals<-predict(treefit2,newdata=newSpamdatasub0, type="class")#
truth<-newSpamdatasub0$SpamOrNot#
table(truth,predvals)
lmat <- matrix(c(0,1,10,0), ncol = 2)#
lmat
treefit2.cost<- rpart(as.factor(SpamOrNot)~ ., data=newSpamdatasub0, parms = list(loss = lmat),control=rpart.control(minsplit = 2, minbucket = 1, cp=0))
bestcp2 <- treefit2.cost$cptable[which.min(treefit2.cost$cptable[,"xerror"]),"CP"]#
tree.pruned <- prune(treefit2.cost, cp = bestcp2)#
predvals2<-predict(tree.pruned,newdata=newSpamdatasub0, type="class")#
truth<-newSpamdatasub0$SpamOrNot#
table(truth,predvals2)#
prp(treefit2.cost,type=2,extra=1)
