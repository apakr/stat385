"hello"
install.packages("car","gplots","HH","rrcov","multicomp","effects","MASS","mvoutlier")
11715.25+3841.12-1372.55
load("/home/allen/Desktop/stat385/Alldata.Rdata")
getwd()
setwd("~/Desktop/stat385/homework4/")
getwd()
ls()
dir
dir()
chromoX <- read.table(file="ChromoXmicroarray.txt",header=TRUE)
table(chromoX)
head(chromoX)
BLClabels <- c(rep(1,13),rep(2,14),rep(3,20))
head(BLClabels)
BLClabels
# Q1. Setup
set.seed(2024)
train.set<-sample(c(1:47),27)
train.set
train.set<-sample(c(1:47),27)
# Q1. Setup
set.seed(2024)
train.set<-sample(c(1:47),27)
# Q1. Setup
set.seed(2024)
train.set<-sample(c(1:47),27)
getwd()
setwd("/stat385/lab6")
setwd("/Desktop/stat385/lab6")
setwd("/home/allen/Desktop/stat385/lab6")
chromoX<-read.table(file="ChromoXmicroarray.txt",header=TRUE)
chromoX<-read.table(file="ChromoXmicroarray.txt",header=TRUE)
BLClabels<-c(rep(1,27),rep(2,20))
ttests<-function(x,group)
{
x<-as.numeric(x)
pvalue<-t.test(x ~ group)$p.value;
return(pvalue)
}
pvalues<-apply(chromoX[,c(3:49)],1,ttests,group=BLClabels)
smallpvals<-order(pvalues)[1:2]
features2<-chromoX[smallpvals,c(3:49)]
plot(t(features2),col=BLClabels,pch=BLClabels)
legend("topleft",c("non-BLC","BLC"),col=c(1,2),pch=c(1,2))
normalization<-function(x)
{
norms<-(x-min(x))/(max(x)-min(x))
return(norms)
}
microdata2<-apply(features2,1,normalization)
microdata2<-data.frame(gene20475=microdata2[,1],gene20947=microdata2[,2],group=BLClabels)
set.seed(20232024)
train.set <- sample(c(1:47), 30)
training.dat <- microdata2[train.set,]
test.dat <- microdata2[-train.set,]
pvalues<-apply(chromoX[,c(3:49)],1,ttests,group=BLClabels)
smallpvals<-order(pvalues)[1:2]
smallpvals
set.seed(20232024)
train.set <- sample(c(1:47), 30)
training.dat <- microdata2[train.set,]
test.dat <- microdata2[-train.set,]
View(training.dat)
View(test.dat)
## LDA method for classification
library(MASS)
z<-lda(group~ ., microdata2,prior=c(1/2,1/2),subset=train.set)
z
## LDA step-by-step
groupmeans<-aggregate(training.dat[,1:2], list(training.dat$group), mean)
group1<-(training.dat$group==1)
group2<-(training.dat$group==2)
S1<-cov(training.dat[group1,1:2])
S2<-cov(training.dat[group2,1:2])
n1<-length(group1)
n2<-length(group2)
Spooled<-((n1-1)*S1+(n2-1)*S2)/(n1+n2-2)
invSn<-solve(Spooled)
ahat<-as.numeric(groupmeans[1,2:3]-groupmeans[2,2:3])%*%invSn
mhat<-ahat%*%as.numeric(groupmeans[1,2:3]+groupmeans[2,2:3])/2
## Naive Bayes for classification (without smoothing)
## install.packages("e1071")
library(e1071)
nbmodel <- naiveBayes(group ~ ., data = microdata2, subset=train.set)
## KNN method for classification
library(class)
knn.pred3<- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat[,3], k=3)
par(mfrow=c(2,2))
## separation line for LDA
plot(training.dat[,1:2], col=as.numeric(training.dat[,3])+1, pch = 19, main="LDA method")
abline(a=mhat/ahat[2],b=-ahat[1]/ahat[2])
## separation curve for NB
px1<-seq(min(microdata2$gene20475),max(microdata2$gene20475),length=100)
px2<-seq(min(microdata2$gene20947),max(microdata2$gene20947),length=100)
xgrid<-expand.grid(gene20475=px1,gene20947=px2)
nbpred <- predict(nbmodel, xgrid)
plot(xgrid, col = as.numeric(nbpred)+1, pch = 20, cex = .2, main="NB method")
points(training.dat[,1:2], col=as.numeric(training.dat[,3])+1, pch = 19)
## prediction using LDA
truth <- test.dat[,3]
predgroups<-predict(z,microdata2[-train.set,])$class
table(truth,predgroups)
## separation plane for KNN (k=3)
knn.pred.grid3 <- knn(train=training.dat[,1:2], test=xgrid, cl=training.dat[,3], k=3)
plot(xgrid, col = as.numeric(knn.pred.grid3)+1, pch = 20, cex = .2, main="KNN k=3")
points(training.dat[,1:2], col=as.numeric(training.dat[,3])+1, pch = 19)
## separation plane for KNN (k=8)
knn.pred.grid8 <- knn(train=training.dat[,1:2], test=xgrid, cl=training.dat[,3], k=8)
plot(xgrid, col = as.numeric(knn.pred.grid8)+1, pch = 20, cex = .2, main="KNN k=8")
points(training.dat[,1:2], col=as.numeric(training.dat[,3])+1, pch = 19)
## prediction using Naive Bayes
nbpred.test <- predict(nbmodel, test.dat)
table(truth, nbpred.test)
## prediction using KNN (k=3)
knn.pred.test3 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat[,3], k=3)
table(truth, knn.pred.test3)
## prediction using KNN (k=8)
knn.pred.test8 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat[,3], k=8)
table(truth, knn.pred.test8)
table(truth, knn.pred)
table(truth, knn.pred3)
table(truth, nbmodel)
knn.pred8<- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat[,3], k=8)
table(truth, knn.pred8)
## prediction using KNN (k=8)
table(truth, knn.pred8)
setwd("~/Desktop/stat385/homework4/")
getwd()
chromoX <- read.table(file="ChromoXmicroarray.txt",header=TRUE)
chromoX <- read.table(file="ChromoXmicroarray.txt",header=TRUE)
head(chromoX)
BLClabels <- c(rep(1,13),rep(2,14),rep(3,20))
BLClabels
# Q1. Setup
set.seed(2024)
train.set<-sample(c(1:47),27)
training.dat <- chromoX[train.set,]
test.dat <- chromoX[-train.set,]
View(test.dat)
test.set <- setdiff(1:47, train.set)
test.dat <- chromoX[test.set,]
# Q2. Perform ANOVA to select most relevant genes
anova_test <- function(x, group) {
x <- as.numeric(x)
aov_result <- aov(x ~ group)
return(summary(aov_result)[[1]]["Pr(>F)", 1])
}
pvalues <- apply(training.dat, 1, anova_test, group=BLClabels[train.set])
training.dat <- chromoX[train.set,3:49]
test.dat <- chromoX[test.set,3:49]
# Q2. Perform ANOVA to select most relevant genes
anova_test <- function(x, group) {
x <- as.numeric(x)
aov_result <- aov(x ~ group)
return(summary(aov_result)[[1]]["Pr(>F)", 1])
}
pvalues <- apply(training.dat, 1, anova_test, group=BLClabels[train.set])
chromoX <- read.table(file="ChromoXmicroarray.txt",header=TRUE)
head(chromoX)
BLClabels <- c(rep(1,13),rep(2,14),rep(3,20))
BLClabels
# Q1. Setup
set.seed(2024)
train.set<-sample(c(1:47),27)
test.set <- setdiff(1:47, train.set)
training.dat <- chromoX[train.set,3:49]
test.dat <- chromoX[test.set,3:49]
# Q2. Perform ANOVA to select most relevant genes
anova_test <- function(x, group) {
x <- as.numeric(x)
aov_result <- aov(x ~ group)
return(summary(aov_result)[[1]]["Pr(>F)", 1])
}
pvalues <- apply(training.dat, 1, anova_test, group=BLClabels[train.set])
# Q2. Perform ANOVA to select most relevant genes
anova_test <- function(x, group) {
x <- as.numeric(x)
aov_result <- aov(x ~ factor(group))
return(summary(aov_result)[[1]]["Pr(>F)", 1])
}
pvalues <- apply(t(training.dat), 1, anova_test, group=BLClabels[train.set])
smallpvals <- order(pvalues)[2:3]
features2 <- chromoX[smallpvals, 3:49]
# Normalize selected features
normalization <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
microdata2 <- apply(features2, 1, normalization)
microdata2 <- data.frame(gene1=microdata2[,1], gene2=microdata2[,2], group=BLClabels)
# Define training and test sets
training.dat <- microdata2[train.set, ]
test.dat <- microdata2[test.set, ]
# Q3 Classification Methods
library(MASS)  # LDA
library(e1071) # Naive Bayes
library(class) # KNN
# Logistic Regression: Combining normal & non-BLC into one group
binary_labels <- ifelse(training.dat$group == 3, 1, 0)
logit_model <- glm(binary_labels ~ ., data=training.dat, family=binomial)
# LDA
lda_model <- lda(group ~ ., data=training.dat)
# Naive Bayes
nb_model <- naiveBayes(group ~ ., data=training.dat)
# KNN for k=4, k=8, k=12
knn_pred4 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=4)
knn_pred8 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=8)
knn_pred12 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=12)
logit_model
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression boundary
plot(training.dat[,1:2], col=training.dat$group, pch=19, main="Logistic Regression")
abline(logit_model, col='red')
# LDA boundary
plot(training.dat[,1:2], col=training.dat$group, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
px1 <- seq(min(microdata2$gene1), max(microdata2$gene1), length=100)
px2 <- seq(min(microdata2$gene2), max(microdata2$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
nb_pred_grid <- predict(nb_model, xgrid)$class
plot(xgrid, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat[,1:2], col=training.dat$group, pch=19)
# Q3 Classification Methods
library(MASS)  # LDA
library(e1071) # Naive Bayes
library(class) # KNN
# Logistic Regression: Combining normal & non-BLC into one group
binary_labels <- ifelse(training.dat$group == 3, 1, 0)
logit_model <- glm(binary_labels ~ ., data=training.dat, family=binomial)
table(training.dat$group, binary_labels)
# Q3. Classification methods
library(MASS)  # LDA
library(e1071) # Naive Bayes
library(class) # KNN
# Logistic Regression: Combining normal & non-BLC into one group
binary_labels <- ifelse(training.dat$group == 3, 1, 0)
# Standard Logistic Regression with small epsilon adjustment
logit_model <- glm(binary_labels ~ ., data=training.dat, family=binomial, control=list(epsilon=1e-8, maxit=50))
# LDA
lda_model <- lda(group ~ ., data=training.dat)
# Naive Bayes
nb_model <- naiveBayes(group ~ ., data=training.dat)
# KNN for k=4, k=8, k=12
knn_pred4 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=4)
knn_pred8 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=8)
knn_pred12 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=12)
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression boundary
plot(training.dat[,1:2], col=training.dat$group, pch=19, main="Logistic Regression")
abline(logit_model, col='red')
# Q3. Classification methods
library(MASS)  # LDA
library(e1071) # Naive Bayes
library(class) # KNN
# Logistic Regression
logit_model <- glm(group ~ ., data=training.dat, family=binomial, control=list(epsilon=1e-8, maxit=50))
# LDA
lda_model <- lda(group ~ ., data=training.dat)
# Logistic Regression
logit_model <- glm(group ~ ., data=training.dat, family=binomial, control=list(epsilon=1e-8, maxit=50))
# Logistic Regression
training.dat$group <- as.numeric(as.character(training.dat$group))
logit_model <- glm(group ~ ., data=training.dat, family=binomial, control=list(epsilon=1e-8, maxit=50))
# Logistic Regression
training.dat$group <- as.numeric(training.dat$group == 1)
logit_model <- glm(group ~ ., data=training.dat, family=binomial, control=list(epsilon=1e-8, maxit=50))
# LDA
lda_model <- lda(group ~ ., data=training.dat)
# Naive Bayes
nb_model <- naiveBayes(group ~ ., data=training.dat)
# KNN for k=4, k=8, k=12
knn_pred4 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=4)
knn_pred8 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=8)
knn_pred12 <- knn(train=training.dat[,1:2], test=test.dat[,1:2], cl=training.dat$group, k=12)
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression decision boundary
plot(training.dat[,1:2], col=training.dat$group, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
contour(px1, px2, matrix(xgrid$prob, length(px1), length(px2)), levels=0.5, add=TRUE, col="red")
# Logistic Regression decision boundary
plot(training.dat[,1:2], col=training.dat$group, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
contour(px1, px2, matrix(xgrid$prob, length(px1), length(px2)), levels=0.5, add=TRUE, col="red")
# Logistic Regression decision boundary
plot(training.dat[,1:2], col=training.dat$group, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
contour(px1, px2, matrix(xgrid$prob, length(px1), length(px2)), levels=0.5, add=TRUE, col="red")
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)$class
plot(xgrid, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=4
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=xgrid, cl=training.dat$group, k=4)
plot(xgrid, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=4
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=4)
plot(xgrid, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=4
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=4)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q4. Plot decision boundaries
par(mfrow=c(2,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=4
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=4)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q4. Plot decision boundaries
par(mfrow=c(3,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=4
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=4)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=8
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=8)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=12
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=12)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q4. Plot decision boundaries
par(mfrow=c(3,2))
# Logistic Regression decision boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="Logistic Regression")
px1 <- seq(min(training.dat$gene1), max(training.dat$gene1), length=100)
px2 <- seq(min(training.dat$gene2), max(training.dat$gene2), length=100)
xgrid <- expand.grid(gene1=px1, gene2=px2)
xgrid$prob <- predict(logit_model, xgrid, type="response")
# Reshape probability matrix correctly
prob_matrix <- matrix(xgrid$prob, length(px1), length(px2))
contour(px1, px2, prob_matrix, levels=0.5, add=TRUE, col="red")
# LDA boundary
plot(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19, main="LDA")
abline(lda_model)
# Naive Bayes boundary
nb_pred_grid <- predict(nb_model, xgrid)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(nb_pred_grid), pch=20, cex=0.2, main="Naive Bayes")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=4
knn_pred_grid4 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=4)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid4), pch=20, cex=0.2, main="KNN k=4")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=8
knn_pred_grid8 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=8)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid8), pch=20, cex=0.2, main="KNN k=8")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# KNN boundary for k=12
knn_pred_grid12 <- knn(train=training.dat[,1:2], test=as.matrix(xgrid[,1:2]), cl=training.dat$group, k=12)
plot(xgrid$gene1, xgrid$gene2, col=as.numeric(knn_pred_grid12), pch=20, cex=0.2, main="KNN k=12")
points(training.dat$gene1, training.dat$gene2, col=training.dat$group + 1, pch=19)
# Q5. Predictions & Performance Evaluation
truth <- test.dat$group
# Logistic Regression Predictions
logit_pred <- predict(logit_model, test.dat, type="response")
logit_pred_class <- ifelse(logit_pred > 0.5, 1, 0)
table(truth, logit_pred_class)
# LDA Predictions
lda_pred <- predict(lda_model, test.dat)$class
table(truth, lda_pred)
# Naive Bayes Predictions
nb_pred <- predict(nb_model, test.dat)
table(truth, nb_pred)
# KNN Predictions
table(truth, knn_pred4)
# K = 8
table(truth, knn_pred8)
# K = 12
table(truth, knn_pred12)
